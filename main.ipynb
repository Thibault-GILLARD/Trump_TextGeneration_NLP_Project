{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM for Trump text generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://miro.medium.com/v2/resize:fit:984/1*Mb_L_slY9rjMr8-IADHvwg.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow will be used for the integration of the LSTM model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = 'Trump Rally Speeches/'\n",
    "files = os.listdir(path)\n",
    "files = [path + file for file in files]\n",
    " \n",
    "dates = []\n",
    "locations = []\n",
    "years = []\n",
    "days = []\n",
    "months = []\n",
    "speeches_text = []\n",
    " \n",
    "month_ab = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep','Oct', 'Nov', 'Dec']\n",
    "\n",
    "for file in files:\n",
    "    for month in month_ab:\n",
    "        if month in file:\n",
    "            locations.append(file[file.find('/')+1:file.find(month)])\n",
    "            break\n",
    "    for i, mont in enumerate(month_ab):\n",
    "        if month in file:\n",
    "            date = file[file.find(month):file.find('.txt')]\n",
    "            dates.append(date)\n",
    "            months.append(date[:3])\n",
    "            days.append(str(date[3]))\n",
    "            years.append(date[-4:])\n",
    "            break   \n",
    "        \n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        speeches_text.append(f.read())     \n",
    "        \n",
    "import pandas as pd\n",
    " \n",
    "df = pd.DataFrame({'Speech':files, 'Date':dates, 'Location':locations, 'Year':years, 'Month':months, 'Day':days, 'Speech_Text':speeches_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thank thank thank vice president pence hes good guy weve done great job together merry christmas mic\n",
      "Thank you. Thank you. Thank you to Vice President Pence. He's a good guy. We've done a great job tog\n",
      "thank thank thank vice president pence hes good guy weve done great job together merry christmas mic\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import preprocessing_pipline\n",
    "\n",
    "preprocessing = preprocessing_pipline(df['Speech_Text'])\n",
    "df['Speech_Text_prepro'] = preprocessing.preprocess_light()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text corpus type <class 'list'>\n",
      "text corpus type <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "text_corpus = [word for speech in df['Speech_Text'].str.split() for word in speech]\n",
    "train_corpus, test_corpus = train_test_split(text_corpus, test_size=0.2, random_state=42)\n",
    "print(\"text corpus type\",type(text_corpus))\n",
    "print(\"text corpus type\",type(text_corpus[0]))\n",
    "\n",
    "\n",
    "\n",
    "# Preprocess text \n",
    "text_corpus_prepro = [word for speech in df['Speech_Text_prepro'].str.split() for word in speech]\n",
    "train_corpus_prepro, test_corpus_prepro = train_test_split(text_corpus_prepro, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Create a tokenizer and fit it on your text corpus\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_corpus)\n",
    "\n",
    "input = []\n",
    "output = []\n",
    "\n",
    "lenght_of_sequences = 10\n",
    "\n",
    "for i in range(lenght_of_sequences, len(train_corpus)):\n",
    "    input.append(train_corpus[i-lenght_of_sequences:i])\n",
    "    output.append(train_corpus[i])\n",
    "\n",
    "input = tokenizer.texts_to_sequences(input)\n",
    "output = tokenizer.texts_to_sequences(output)\n",
    "\n",
    "# pad \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "input = pad_sequences(input, maxlen=lenght_of_sequences, padding='pre')\n",
    "output = pad_sequences(output, maxlen=1, padding='pre')\n",
    "# Convert your lists of input sequences into numpy arrays\n",
    "import numpy as np\n",
    " \n",
    "input = np.array(input)\n",
    "output = np.array(output)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split your data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(input, output, test_size=0.2, random_state=42)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: <class 'numpy.ndarray'>\n",
      "X_train Shape: (296371, 1)\n",
      "X_train Example Sequence: [46]\n",
      "y_train Data Type: <class 'numpy.ndarray'>\n",
      "y_train Shape: (237096, 1)\n",
      "y_train Example Value: [3]\n"
     ]
    }
   ],
   "source": [
    "print(\"output:\", type(output))\n",
    "print(\"X_train Shape:\", output.shape)\n",
    "print(\"X_train Example Sequence:\", output[1])\n",
    "\n",
    "print(\"y_train Data Type:\", type(y_train))\n",
    "print(\"y_train Shape:\", y_train.shape)\n",
    "print(\"y_train Example Value:\", y_train[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "class my_model_LSTM:\n",
    "    def __init__(self, n, num_unique_words, max_sequence_length):\n",
    "        self.n = n\n",
    "        self.num_unique_words = num_unique_words\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.model = self.build_model()\n",
    "        \n",
    "    def build_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(Embedding(self.num_unique_words, self.n))\n",
    "        model.add(LSTM(units=self.n))\n",
    "        model.add(Dense(units=self.num_unique_words, activation='softmax'))\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "     \n",
    "    def train(self, X_train, y_train, epochs=10):\n",
    "        self.model.fit(X_train, y_train, epochs=epochs)\n",
    "         \n",
    "    def predict(self, test_corpus):\n",
    "        return self.model.predict(test_corpus)\n",
    "     \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        return self.model.evaluate(X_test, y_test)\n",
    "     \n",
    "    def save(self, path):\n",
    "        self.model.save(path)\n",
    "         \n",
    "    def load(self, path):\n",
    "        self.model = tf.keras.models.load_model(path)\n",
    "         \n",
    "    def generate_text(self, start_string, num_generate=1000):\n",
    "        # Vectorize your start string using the tokenizer you built earlier\n",
    "        input_eval = [tokenizer.word_index[word] for word in start_string.split()]\n",
    "        input_eval = tf.expand_dims(input_eval, 0)\n",
    "         \n",
    "        # Empty string to store your results\n",
    "        text_generated = []\n",
    "         \n",
    "        # Here batch size == 1\n",
    "        self.model.reset_states()\n",
    "        for i in range(num_generate):\n",
    "            predictions = self.model(input_eval)\n",
    "            predictions = tf.squeeze(predictions, 0)\n",
    "             \n",
    "            predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "             \n",
    "            input_eval = tf.expand_dims([predicted_id], 0)\n",
    "             \n",
    "            text_generated.append(tokenizer.index_word[predicted_id])\n",
    "             \n",
    "        return (start_string + ' '.join(text_generated))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7410/7410 [==============================] - 482s 65ms/step - loss: 6.4583 - accuracy: 0.0374\n",
      "Epoch 2/3\n",
      "7410/7410 [==============================] - 463s 63ms/step - loss: 6.3809 - accuracy: 0.0379\n",
      "Epoch 3/3\n",
      "7410/7410 [==============================] - 482s 65ms/step - loss: 6.3502 - accuracy: 0.0380\n"
     ]
    }
   ],
   "source": [
    "num_unique_words = len(tokenizer.word_index) + 1\n",
    "max_sequence_length = 15\n",
    "model_LSTM = my_model_LSTM(256, num_unique_words, max_sequence_length)\n",
    "model_LSTM.train(X_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1853/1853 [==============================] - 26s 14ms/step - loss: 6.4546 - accuracy: 0.0384\n",
      "1853/1853 [==============================] - 28s 15ms/step - loss: 6.4546 - accuracy: 0.0384\n",
      "LSTM Model Accuracy: 0.038363561034202576\n",
      "1853/1853 [==============================] - 27s 14ms/step - loss: 6.4546 - accuracy: 0.0384\n",
      "LSTM Model Loss: 6.4545793533325195\n",
      "1853/1853 [==============================] - 25s 14ms/step - loss: 6.4546 - accuracy: 0.0384\n",
      "LSTM Model Perplexity: 635.606304337891\n"
     ]
    }
   ],
   "source": [
    "# test \n",
    "model_LSTM.evaluate(X_test, y_test)\n",
    "print(model_LSTM.evaluate(X_test, y_test))\n",
    "# print metrics\n",
    "print(\"LSTM Model Accuracy:\", model_LSTM.evaluate(X_test, y_test)[1])\n",
    "print(\"LSTM Model Loss:\", model_LSTM.evaluate(X_test, y_test)[0])\n",
    "# perplextiy\n",
    "print(\"LSTM Model Perplexity:\", np.exp(model_LSTM.evaluate(X_test, y_test)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1853/1853 [==============================] - 25s 13ms/step - loss: 6.4546 - accuracy: 0.0384\n",
      "[6.4545793533325195, 0.038363561034202576]\n"
     ]
    }
   ],
   "source": [
    "print(model_LSTM.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/Trump_TextGeneration_NLP_Project/myenv/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'my_model_LSTM' object has no attribute 'text_corpus'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_LSTM\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mmodel_LSTM.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m model_LSTM\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mmodel_LSTM.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m model_LSTM\u001b[39m.\u001b[39;49mgenerate_text(\u001b[39m'\u001b[39;49m\u001b[39mI\u001b[39;49m\u001b[39m'\u001b[39;49m, num_generate\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[22], line 35\u001b[0m, in \u001b[0;36mmy_model_LSTM.generate_text\u001b[0;34m(self, start_string, num_generate)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_text\u001b[39m(\u001b[39mself\u001b[39m, start_string, num_generate\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m):\n\u001b[0;32m---> 35\u001b[0m     input_eval \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_corpus\u001b[39m.\u001b[39mindex(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m start_string\u001b[39m.\u001b[39msplit()]\n\u001b[1;32m     36\u001b[0m     input_eval \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mexpand_dims(input_eval, \u001b[39m0\u001b[39m)\n\u001b[1;32m     37\u001b[0m     text_generated \u001b[39m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[22], line 35\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_text\u001b[39m(\u001b[39mself\u001b[39m, start_string, num_generate\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m):\n\u001b[0;32m---> 35\u001b[0m     input_eval \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtext_corpus\u001b[39m.\u001b[39mindex(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m start_string\u001b[39m.\u001b[39msplit()]\n\u001b[1;32m     36\u001b[0m     input_eval \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mexpand_dims(input_eval, \u001b[39m0\u001b[39m)\n\u001b[1;32m     37\u001b[0m     text_generated \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'my_model_LSTM' object has no attribute 'text_corpus'"
     ]
    }
   ],
   "source": [
    "model_LSTM.save('model_LSTM.h5')\n",
    "model_LSTM.load('model_LSTM.h5')\n",
    "model_LSTM.generate_text('I', num_generate=1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "262f45c2f7c4647a52b21fdf148897939a0a772c971848ae3fddd645c697c1d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
